{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models that we built , needs proper evaluation to understand how they will perform on real world data in production. That's why we have some set evaluation techniques in place for specific kinds of machine learning problems. We will discuss all of them one by one here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regression Problems\n",
    "\n",
    "Regression problems are those kind of problems where our target variable or ourput is a continuous variable. Like predicting weather temparature , salary etc etc. And there are some set model evaluation techniques present for such problems. Let's look into it.\n",
    "\n",
    "    -   Mean Squared Error (MSE)\n",
    "        \n",
    "    In regression problems let's understand the error part first. We get an actual value(target variable) present in our test data and our regression model will also predict a value for the target variable. Now this predicted value and the actual value will continue to have some differences. This differences are called errors. In certain cases this differences can be positive , in some cases it can be negative as well. So to bring all the values in the positive section , we square up the errors. And at the end we go ahead find out the mean of all the errors. That's called mean Squared Error or MSE. Below is given the formual of MSE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](Mean%20Squared%20Error%20Formual.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand mean squared error with code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the neccesary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets import our dataset , we will work with boston data itself\n",
    "df = pd.read_csv('BostonHousing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the missing value level present in the data is as below crim       0\n",
      "zn         0\n",
      "indus      0\n",
      "chas       0\n",
      "nox        0\n",
      "rm         0\n",
      "age        0\n",
      "dis        0\n",
      "rad        0\n",
      "tax        0\n",
      "ptratio    0\n",
      "b          0\n",
      "lstat      0\n",
      "medv       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's check few details of the data\n",
    "print(f'the missing value level present in the data is as below {df.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's divide our data in x and y for feature and target variable identification\n",
    "x = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio       b  lstat  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      24.0\n",
       "1      21.6\n",
       "2      34.7\n",
       "3      33.4\n",
       "4      36.2\n",
       "       ... \n",
       "501    22.4\n",
       "502    20.6\n",
       "503    23.9\n",
       "504    22.0\n",
       "505    11.9\n",
       "Name: medv, Length: 506, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to scale our features so that it remains in the same scale with standaradscaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41978194,  0.28482986, -1.2879095 , ..., -1.45900038,\n",
       "         0.44105193, -1.0755623 ],\n",
       "       [-0.41733926, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.44105193, -0.49243937],\n",
       "       [-0.41734159, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.39642699, -1.2087274 ],\n",
       "       ...,\n",
       "       [-0.41344658, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.98304761],\n",
       "       [-0.40776407, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.4032249 , -0.86530163],\n",
       "       [-0.41500016, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.66905833]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's go ahead and do our train test split\n",
    "xtrain,xtest,ytrain,ytest = tts(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's train our model\n",
    "lr = lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668759493535632"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(xtest,ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our linear regression model is built , let's build a prediction variable as ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = lr.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.99672362, 36.02556534, 14.81694405, 25.03197915, 18.76987992,\n",
       "       23.25442929, 17.66253818, 14.34119   , 23.01320703, 20.63245597,\n",
       "       24.90850512, 18.63883645, -6.08842184, 21.75834668, 19.23922576,\n",
       "       26.19319733, 20.64773313,  5.79472718, 40.50033966, 17.61289074,\n",
       "       27.24909479, 30.06625441, 11.34179277, 24.16077616, 17.86058499,\n",
       "       15.83609765, 22.78148106, 14.57704449, 22.43626052, 19.19631835,\n",
       "       22.43383455, 25.21979081, 25.93909562, 17.70162434, 16.76911711,\n",
       "       16.95125411, 31.23340153, 20.13246729, 23.76579011, 24.6322925 ,\n",
       "       13.94204955, 32.25576301, 42.67251161, 17.32745046, 27.27618614,\n",
       "       16.99310991, 14.07009109, 25.90341861, 20.29485982, 29.95339638,\n",
       "       21.28860173, 34.34451856, 16.04739105, 26.22562412, 39.53939798,\n",
       "       22.57950697, 18.84531367, 32.72531661, 25.0673037 , 12.88628956,\n",
       "       22.68221908, 30.48287757, 31.52626806, 15.90148607, 20.22094826,\n",
       "       16.71089812, 20.52384893, 25.96356264, 30.61607978, 11.59783023,\n",
       "       20.51232627, 27.48111878, 11.01962332, 15.68096344, 23.79316251,\n",
       "        6.19929359, 21.6039073 , 41.41377225, 18.76548695,  8.87931901,\n",
       "       20.83076916, 13.25620627, 20.73963699,  9.36482222, 23.22444271,\n",
       "       31.9155003 , 19.10228271, 25.51579303, 29.04256769, 20.14358566,\n",
       "       25.5859787 ,  5.70159447, 20.09474756, 14.95069156, 12.50395648,\n",
       "       20.72635294, 24.73957161, -0.164237  , 13.68486682, 16.18359697,\n",
       "       22.27621999, 24.47902364])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173    23.6\n",
       "274    32.4\n",
       "491    13.6\n",
       "72     22.8\n",
       "452    16.1\n",
       "       ... \n",
       "412    17.9\n",
       "436     9.6\n",
       "411    17.2\n",
       "86     22.5\n",
       "75     21.4\n",
       "Name: medv, Length: 102, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "print(len(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "print(len(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "print(len(ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='medv'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets visualiza our model prediction and actual values\n",
    "import seaborn as sns\n",
    "sns.regplot(x = ytest , y = ypred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a list of errors , which is simply substracting the actual values from the predicted values\n",
    "changes = list(ypred-ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.396723619824883,\n",
       " 3.625565335672313,\n",
       " 1.216944045388285,\n",
       " 2.2319791503995674,\n",
       " 2.669879915248149,\n",
       " 3.2544292914679716,\n",
       " -0.13746181779418976,\n",
       " 0.3411899997547092,\n",
       " 3.413207026913337,\n",
       " 3.8324559727508465,\n",
       " 3.408505116349641,\n",
       " -0.2611635466075555,\n",
       " -13.088421842193625,\n",
       " 0.5583466809972926,\n",
       " 0.7392257593035794,\n",
       " -3.6068026717863546,\n",
       " 1.8477331297073185,\n",
       " -4.405272821115485,\n",
       " -9.499660339492422,\n",
       " 3.5128907427671674,\n",
       " 2.0490947868518354,\n",
       " 0.9662544095122598,\n",
       " -1.3582072271767238,\n",
       " 1.7607761605923677,\n",
       " 3.660584986887809,\n",
       " 2.036097647919295,\n",
       " 2.4814810552120647,\n",
       " -0.3229555113683009,\n",
       " 0.7362605243684825,\n",
       " 0.8963183464667104,\n",
       " -0.6661654488658755,\n",
       " 1.4197908067564846,\n",
       " 10.939095624449543,\n",
       " -3.0983756592133993,\n",
       " -2.3308828901820533,\n",
       " -2.448745890731942,\n",
       " -3.4665984706249944,\n",
       " 0.6324672853666868,\n",
       " -0.6342098892753363,\n",
       " 1.2322924971596656,\n",
       " -5.757950450869547,\n",
       " 4.055763011339312,\n",
       " -7.327488388980569,\n",
       " -0.07254953572099865,\n",
       " 4.676186138004901,\n",
       " 1.893109908316207,\n",
       " 0.9700910916451431,\n",
       " 1.7034186116046754,\n",
       " 0.39485982256238117,\n",
       " 5.953396377335693,\n",
       " 2.388601728145286,\n",
       " -1.055481435365131,\n",
       " 0.8473910498621962,\n",
       " -0.27437588371694943,\n",
       " -3.9606020216584454,\n",
       " 1.3795069680653747,\n",
       " 0.44531366626455693,\n",
       " 4.22531661496572,\n",
       " 1.1673036969031934,\n",
       " -5.613710435657753,\n",
       " -2.3177809226427364,\n",
       " -4.917122425865042,\n",
       " 0.02626806478218313,\n",
       " -4.298513929639672,\n",
       " -3.8790517385940504,\n",
       " -3.2891018813931687,\n",
       " 7.423848928753118,\n",
       " 1.1635626380438566,\n",
       " -0.18392022376720618,\n",
       " -1.1021697741712622,\n",
       " 0.5123262743265968,\n",
       " 3.7811187778861104,\n",
       " 0.21962332247759342,\n",
       " -4.919036556871728,\n",
       " 2.9931625127084764,\n",
       " 1.1992935939490827,\n",
       " 1.503907303225084,\n",
       " -7.0862277486752845,\n",
       " 7.86548694981486,\n",
       " 1.8793190117150314,\n",
       " -0.06923083841214961,\n",
       " -3.943793731695459,\n",
       " -0.16036301161222966,\n",
       " -0.3351777834577092,\n",
       " 3.824442713498069,\n",
       " 2.915500297944522,\n",
       " 2.702282710679661,\n",
       " 0.5157930325947824,\n",
       " 4.042567694388353,\n",
       " 3.0435856607765217,\n",
       " 2.385978704279765,\n",
       " -4.698405529660532,\n",
       " 0.4947475582042209,\n",
       " -2.2493084376549604,\n",
       " -14.996043515817975,\n",
       " -2.273647060854195,\n",
       " -25.260428393480627,\n",
       " -18.06423699568657,\n",
       " 4.084866815285885,\n",
       " -1.016403028286554,\n",
       " -0.22378000646660112,\n",
       " 3.0790236390206616]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_value</th>\n",
       "      <th>predicted_value</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>23.6</td>\n",
       "      <td>28.996724</td>\n",
       "      <td>5.396724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>32.4</td>\n",
       "      <td>36.025565</td>\n",
       "      <td>3.625565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "      <td>14.816944</td>\n",
       "      <td>1.216944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22.8</td>\n",
       "      <td>25.031979</td>\n",
       "      <td>2.231979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.769880</td>\n",
       "      <td>2.669880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual_value  predicted_value     error\n",
       "173          23.6        28.996724  5.396724\n",
       "274          32.4        36.025565  3.625565\n",
       "491          13.6        14.816944  1.216944\n",
       "72           22.8        25.031979  2.231979\n",
       "452          16.1        18.769880  2.669880"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe storing actual , predicted and changed values \n",
    "ch_df = pd.DataFrame(data = {\"actual_value\":ytest,\n",
    "                                 \"predicted_value\":ypred,\n",
    "                                 \"error\":changes})\n",
    "ch_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see through visualization that there are errors present in the data and also we have checked through the list called 'changes' that how scattered our errors are , lets with the help of numpy first find out our mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squaring all the errors\n",
    "sq_error_list = []\n",
    "for i in changes:\n",
    "    sq_error_list.append(np.square(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29.124625828775784,\n",
       " 13.144724003228692,\n",
       " 1.480952809606004,\n",
       " 4.981730927818375,\n",
       " 7.128258761845464,\n",
       " 10.591310013164723,\n",
       " 0.018895751351283022,\n",
       " 0.11641061593261846,\n",
       " 11.649982208570583,\n",
       " 14.687718783073636,\n",
       " 11.61790712818168,\n",
       " 0.0682063980766368,\n",
       " 171.30678631921117,\n",
       " 0.3117510161806924,\n",
       " 0.5464547232179534,\n",
       " 13.009025513205186,\n",
       " 3.4141177186180025,\n",
       " 19.406428628458784,\n",
       " 90.24354656572528,\n",
       " 12.340401370619261,\n",
       " 4.198789445503369,\n",
       " 0.933647583901886,\n",
       " 1.8447268719550847,\n",
       " 3.1003326877103996,\n",
       " 13.39988244622842,\n",
       " 4.1456936318624855,\n",
       " 6.157748227376382,\n",
       " 0.10430026232316074,\n",
       " 0.5420795597433529,\n",
       " 0.8033865782128179,\n",
       " 0.44377640526267337,\n",
       " 2.0158059349502295,\n",
       " 119.66381308085113,\n",
       " 9.599931725606067,\n",
       " 5.433015047743442,\n",
       " 5.996356437376573,\n",
       " 12.01730495653955,\n",
       " 0.4000148670591061,\n",
       " 0.4022221836546343,\n",
       " 1.5185447985560045,\n",
       " 33.153993394668824,\n",
       " 16.449213604148127,\n",
       " 53.692086090645056,\n",
       " 0.005263435133332459,\n",
       " 21.866716797269195,\n",
       " 3.5838651249649978,\n",
       " 0.9410767260892654,\n",
       " 2.9016349663612,\n",
       " 0.15591427947399514,\n",
       " 35.442928425673756,\n",
       " 5.7054182156986455,\n",
       " 1.1140410604004372,\n",
       " 0.718071591386555,\n",
       " 0.07528212556545695,\n",
       " 15.686368373964966,\n",
       " 1.9030394749409225,\n",
       " 0.19830426136198118,\n",
       " 17.853300496705373,\n",
       " 1.3625979208038623,\n",
       " 31.513744855412757,\n",
       " 5.372108405366614,\n",
       " 24.178092950944915,\n",
       " 0.0006900112274009697,\n",
       " 18.47722200330629,\n",
       " 15.047042390689525,\n",
       " 10.818191186184082,\n",
       " 55.11353291694883,\n",
       " 1.3538780126515788,\n",
       " 0.033826648710579194,\n",
       " 1.2147782110967311,\n",
       " 0.26247821136537136,\n",
       " 14.296859212482953,\n",
       " 0.04823440377609699,\n",
       " 24.19692064784046,\n",
       " 8.95902182748332,\n",
       " 1.4383051244873073,\n",
       " 2.261737176693745,\n",
       " 50.214623706095594,\n",
       " 61.86588495770788,\n",
       " 3.531839947793562,\n",
       " 0.00479290898724917,\n",
       " 15.553508998160396,\n",
       " 0.025716295493344102,\n",
       " 0.11234414652362301,\n",
       " 14.626362068828472,\n",
       " 8.500141987314597,\n",
       " 7.302331848438217,\n",
       " 0.26604245247332226,\n",
       " 16.342353563712365,\n",
       " 9.263413674484456,\n",
       " 5.692894377276546,\n",
       " 22.07501452114466,\n",
       " 0.24477514634903894,\n",
       " 5.059388447705799,\n",
       " 224.88132112830635,\n",
       " 5.16947095733092,\n",
       " 638.0892426221623,\n",
       " 326.31665823633136,\n",
       " 16.686136898623847,\n",
       " 1.0330751159100773,\n",
       " 0.05007749129419204,\n",
       " 9.480386569648036]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean squared error through numpy method is 24.29111947497352\n"
     ]
    }
   ],
   "source": [
    "# now let's find the mean of this squared list\n",
    "mse_numpy = np.mean(sq_error_list)\n",
    "print(f'the mean squared error through numpy method is {mse_numpy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean squared error through sklearn method is 24.29111947497352\n"
     ]
    }
   ],
   "source": [
    "# now let's find out the MSE through our sklearn method.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_sklearn = mean_squared_error(ytest,ypred)\n",
    "print(f'the mean squared error through sklearn method is {mse_sklearn}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus our theory is proved to be right as in both occasions we have got the same result of mean squared error. Near to 0 MSE indicates more accurate model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -   Mean Absolute Error (MAE)\n",
    "\n",
    "    This simply means the mean of total sum of all errors that has been produced from our model, We will look into it with both with and without sklearn metrics below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean absolute error with numpy method is 3.1890919658878505\n",
      "the mean absolute error with numpy method is 3.1890919658878505\n"
     ]
    }
   ],
   "source": [
    "# finding the mean of all errors with numpy method\n",
    "abs_error_lst = []\n",
    "for i in changes:\n",
    "    abs_error_lst.append(abs(i))\n",
    "mae_numpy = np.mean(abs_error_lst) \n",
    "print(f'the mean absolute error with numpy method is {mae_numpy}')\n",
    "#finding the mean of all errors with sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_sklearn = mean_absolute_error(ytest,ypred)\n",
    "print(f'the mean absolute error with numpy method is {mae_sklearn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
